{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ea21f06-8504-4bac-9542-6014a8a8f4ef",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4496b1cd-6336-4a0e-914a-28087d06fbb0",
   "metadata": {},
   "source": [
    "Web scraping is the process of extracting data from websites. It involves fetching web pages, parsing the HTML content, and extracting the desired information. Web scraping is used to gather data from websites that do not offer official APIs or data feeds. It is commonly used for various purposes like data analysis, research, monitoring, and more.\n",
    "\n",
    "Three areas where web scraping is used:\n",
    "E-commerce Price Comparison: Web scraping is used to collect product prices and details from various e-commerce websites to compare prices and find the best deals.\n",
    "\n",
    "Market Research: Businesses use web scraping to gather information about their competitors, market trends, customer reviews, and other relevant data.\n",
    "\n",
    "News and Social Media Monitoring: Web scraping is used to collect news articles, social media posts, and comments to monitor public sentiment, trends, and emerging topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b5715-4da1-431c-9671-55bf793381a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c6c55b9-0e63-4653-87fc-c431359e3d57",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f29e91d-1887-47dd-9733-713235f01884",
   "metadata": {},
   "source": [
    "Web scraping can be done using various methods:\n",
    "\n",
    "Manual Copy-Paste: Copying data manually from web pages and pasting it into a spreadsheet or text file.\n",
    "\n",
    "Regular Expressions: Using regular expressions to match and extract specific patterns from HTML content.\n",
    "\n",
    "DOM Parsing: Using browser developer tools to inspect the Document Object Model (DOM) and extract data using JavaScript.\n",
    "\n",
    "Web Scraping Libraries: Using programming languages and libraries like Python with BeautifulSoup and Scrapy to automate and simplify the scraping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f41884-8c1e-4b1b-b3bc-d3780a3a2c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4871002f-54d6-4df5-bcc6-c6bc95f7f980",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf66944-254a-4c1b-bffa-9c84b165d444",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library used for web scraping. It provides tools to parse HTML and XML documents, navigate the parsed tree, and search for specific elements or data. Beautiful Soup is used to extract data from HTML documents in a more convenient and readable way than using regular expressions or manual parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c93fa46-1b6b-4133-a66a-3f44f721a410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d41918a-d125-49b8-afce-5249c732d93c",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c737a741-a9ee-4527-ba23-eee85907a6e1",
   "metadata": {},
   "source": [
    "Flask is a micro web framework for Python that is often used to create web applications. In the context of web scraping, Flask can be used to build a simple web interface to display or visualize the scraped data. For example, you could use Flask to create a web page that shows the scraped data in a user-friendly format or generates charts based on the collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f54fdb3-5b0a-4b66-8c27-dfd14cce05e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c26b402-0b45-43fd-b68f-f3bbdc53658f",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2e6812-2aaa-4d70-b1b9-51eea081ec00",
   "metadata": {},
   "source": [
    "If AWS services are being used in a web scraping project, potential services could include:\n",
    "\n",
    "Amazon EC2 (Elastic Compute Cloud): Used for hosting the web scraping script or application.\n",
    "\n",
    "Amazon S3 (Simple Storage Service): Used to store the scraped data or any files generated during the scraping process.\n",
    "\n",
    "Amazon RDS (Relational Database Service): Used to store structured data if necessary.\n",
    "\n",
    "AWS Lambda: Used for serverless execution of code, which can be triggered by events like new data being available for scraping.\n",
    "\n",
    "Amazon CloudWatch: Used for monitoring and logging the scraping activities and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1877b2-ab98-4326-a771-6ec974e2f83f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
